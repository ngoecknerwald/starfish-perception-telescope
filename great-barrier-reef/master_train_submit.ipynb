{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4aa16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a copy of the script that we will use to submit entries\n",
    "\n",
    "%%capture\n",
    "# Remember to set runtime to GPU acceleration\n",
    "\n",
    "# Mount files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set up Kaggle\n",
    "!pip uninstall -y kaggle\n",
    "!pip install --upgrade pip\n",
    "!pip install kaggle==1.5.6\n",
    "!mkdir ~/.kaggle\n",
    "\n",
    "import json\n",
    "token = {\"username\":\"neilgoecknerwald\",\"key\":\"82411b328e32a9330e81f96a6eefe6ac\"}\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(token, file)\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# Download files\n",
    "!kaggle competitions download -c tensorflow-great-barrier-reef\n",
    "\n",
    "%%capture\n",
    "!unzip tensorflow-great-barrier-reef.zip\n",
    "!rm tensorflow-great-barrier-reef.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb82482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone and pull in python files\n",
    "!git config --global user.email \"ngoecknerwald@gmail.com\"\n",
    "!git config --global user.name \"Neil Goeckner-Wald\"\n",
    "\n",
    "!git clone https://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@github.com/ngoecknerwald/tensorflow-experiment.git\n",
    "!rsync tensorflow-experiment/great-barrier-reef/*.py .\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "787201b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List physical devices\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "\n",
    "is_colab = len(tf.config.list_physical_devices('GPU')) > 0\n",
    "\n",
    "# Data locations\n",
    "if is_colab:\n",
    "    datapath='/content'\n",
    "    backbone_weights='drive/MyDrive/trained_backbone.ckpt'\n",
    "    rpn_weights='drive/MyDrive/trained_rpn.ckpt'\n",
    "    class_weights='drive/MyDrive/trained_classifier.ckpt'\n",
    "else:\n",
    "    datapath='tensorflow-great-barrier-reef'\n",
    "    backbone_weights='trained_backbone.ckpt'\n",
    "    rpn_weights='trained_rpn.ckpt'\n",
    "    class_weights='trained_classifier.ckpt'\n",
    "\n",
    "# Keep most dependencies wrapped further down in the util scripts\n",
    "import faster_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d450b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading backbone weights from trained_backbone.ckpt\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the high-level wrapper\n",
    "reload(faster_rcnn)\n",
    "\n",
    "frcnn = faster_rcnn.FasterRCNNWrapper(\n",
    "    input_shape=(720, 1280, 3),\n",
    "    datapath=datapath,\n",
    "    backbone_type='ResNet50',\n",
    "    backbone_weights=backbone_weights if os.path.exists(backbone_weights) else 'finetune',\n",
    "    rpn_weights=rpn_weights if os.path.exists(rpn_weights) else None,\n",
    "    classifier_weights=class_weights if os.path.exists(class_weights) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e01058f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.635009 394 481 75 71 0.619195 522 417 75 71 0.615346 141 421 69 65 0.612049 438 616 59 55 0.516695 394 42 74 70']\n"
     ]
    }
   ],
   "source": [
    "# Check return syntax\n",
    "testval = frcnn.data_loader_full.get_validation().__iter__().next()\n",
    "print(frcnn.predict(testval[0][:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2d38bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.634934 298 418 75 71 0.619280 202 198 75 71 0.615367 493 484 69 65 0.612049 54 178 59 55 0.516916 522 199 74 70']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now enter evaluate mode. This is just the boilerplate code from the competition website.\n",
    "#import greatbarrierreef\n",
    "\n",
    "#env = greatbarrierreef.make_env()\n",
    "#iter_test = env.iter_test()\n",
    "\n",
    "#for (pixel_array, prediction_df) in iter_test:\n",
    "#    prediction_df['annotations'] = model.predict(pixel_array)\n",
    "#    env.predict(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c57ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ed178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
